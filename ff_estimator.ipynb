{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05db81f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c0fe1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92b90009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2+cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose device for torch computing\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.__version__)\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a4f41bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change working directory to labels\n",
    "work_dir = \"D:\\\\UIUC\\\\Fall 2021\\\\Research\"\n",
    "os.chdir(work_dir)\n",
    "\n",
    "# Reads labels into dict of (filename: ff_value)\n",
    "training_data_labels = {}\n",
    "with open(\"training_ff.txt\") as f:\n",
    "    for line in f:\n",
    "        key, val = line.split()\n",
    "        training_data_labels[key] = float(val)\n",
    "        \n",
    "test_data_labels = {}\n",
    "with open(\"test_ff.txt\") as f:\n",
    "    for line in f:\n",
    "        key, val = line.split()\n",
    "        test_data_labels[key] = float(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c6b4ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersect = 0\n",
    "# for i in training_data_labels:\n",
    "#     if i in test_data_labels:\n",
    "#         intersect += 1\n",
    "        \n",
    "# print(len(training_data_labels), len(test_data_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbe4a678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2040/2040 [01:38<00:00, 20.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2040/2040 [01:51<00:00, 18.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# Change directory to data\n",
    "os.chdir(\"D:\\\\UIUC\\\\Fall 2021\\\\Research\\\\rf_without_tgc\")\n",
    "\n",
    "# Iterate thru data to create lists of tensors\n",
    "training_data = []\n",
    "training_labels = []\n",
    "for file in tqdm(os.listdir()):\n",
    "    if file not in training_data_labels:\n",
    "        continue\n",
    "        \n",
    "    file_data = pd.read_csv(file, header=None).T\n",
    "    \n",
    "    x_tensor = file_data.to_numpy().astype(np.float32)\n",
    "    y_tensor = float(training_data_labels[file])\n",
    "    \n",
    "    for x in x_tensor:\n",
    "        training_data.append(x)\n",
    "        training_labels.append(y_tensor)\n",
    "    \n",
    "test_data = []\n",
    "test_labels = []\n",
    "for file in tqdm(os.listdir()):\n",
    "    if file not in test_data_labels:\n",
    "        continue\n",
    "        \n",
    "    file_data = pd.read_csv(file, header=None).T\n",
    "    \n",
    "    x_tensor = file_data.to_numpy().astype(np.float32)\n",
    "    y_tensor = float(test_data_labels[file])\n",
    "\n",
    "    for x in x_tensor:\n",
    "        test_data.append(x)\n",
    "        test_labels.append(y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb897249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(261120, 1024)\n",
      "(261120, 1024)\n"
     ]
    }
   ],
   "source": [
    "# # Create class for DataLoader compatability\n",
    "# class Data():\n",
    "#     def __init__(self, x, y):\n",
    "#         self.x = x\n",
    "#         self.y = y\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.x)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         X = self.x[idx]\n",
    "#         y =  self.y[idx]\n",
    "\n",
    "#         return X, y\n",
    "\n",
    "training_data = np.array(training_data)\n",
    "training_labels = np.array(training_labels)\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(training_data.shape)\n",
    "print(test_data.shape)\n",
    "    \n",
    "# training_data = np.swapaxes(training_data, 1, 2)\n",
    "# test_data = np.swapaxes(test_data, 1, 2)\n",
    "\n",
    "# Create data tensors\n",
    "training_data = torch.Tensor(training_data)\n",
    "training_labels = torch.Tensor(training_labels)\n",
    "\n",
    "test_data = torch.Tensor(test_data)\n",
    "test_labels = torch.Tensor(test_labels)\n",
    "\n",
    "# training_data = (training_data - torch.mean(training_data)) / torch.std(training_data)\n",
    "# test_data = (test_data - torch.mean(test_data)) / torch.std(test_data)\n",
    "\n",
    "train_dataset = TensorDataset(training_data, training_labels)\n",
    "test_dataset = TensorDataset(test_data, test_labels)\n",
    "\n",
    "# # Load tensors into class for torch DataLoaders\n",
    "# train_data = Data(training_data, training_labels)\n",
    "# test_data = Data(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2511a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader Parameters\n",
    "loader_params = {\n",
    "    \"batch_size\":  32, \n",
    "    \"shuffle\":     True,\n",
    "    \"num_workers\": 0\n",
    "}\n",
    "\n",
    "# Create DataLoader for training data\n",
    "loader = DataLoader(train_dataset, **loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4089d68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "pool = 4\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 8, 8, 1, padding='same'),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool1d(pool, stride=pool, padding=0)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(8, 8, 4, 1, padding='same'),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool1d(pool, stride=pool, padding=0)\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(8, 16, 4, 1, padding='same'),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool1d(pool, stride=pool, padding=0)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(256, 32),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# import torch.nn as nn\n",
    "\n",
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "        \n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             nn.Conv2d(1, 8, 16, 1, 'same'),\n",
    "#             nn.Tanh(),\n",
    "#             nn.MaxPool2d(2, stride=2, padding=0)\n",
    "#         )\n",
    "        \n",
    "#         self.conv2 = nn.Sequential(\n",
    "#             nn.Conv2d(8, 8, 8, 1, padding='same'),\n",
    "#             nn.Tanh(),\n",
    "#             nn.MaxPool2d(2, stride=2, padding=0)\n",
    "#         )\n",
    "        \n",
    "#         self.conv3 = nn.Sequential(\n",
    "#             nn.Conv2d(8, 16, 8, 1, padding='same'),\n",
    "#             nn.Tanh(),\n",
    "#             nn.MaxPool2d(2, stride=2, padding=0)\n",
    "#         )\n",
    "        \n",
    "#         self.fc1 = nn.Sequential(\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(65024, 32),\n",
    "#             nn.Tanh()\n",
    "#         )\n",
    "        \n",
    "#         self.fc2 = nn.Linear(32, 2)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.conv3(x)\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09329fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(1, 8, kernel_size=(8,), stride=(1,), padding=same)\n",
       "    (1): Tanh()\n",
       "    (2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv1d(8, 8, kernel_size=(4,), stride=(1,), padding=same)\n",
       "    (1): Tanh()\n",
       "    (2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv1d(8, 16, kernel_size=(4,), stride=(1,), padding=same)\n",
       "    (1): Tanh()\n",
       "    (2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise net and push to computing device\n",
    "cnn = CNN()\n",
    "cnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eec5f8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0918ebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Define optimiser and learning rate\n",
    "optimiser = optim.Adagrad(cnn.parameters(), lr=.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "86eb7dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DUMMY DATA\n",
    "# train_data = []\n",
    "# train_labels = []\n",
    "\n",
    "# test_data = []\n",
    "# test_labels = []\n",
    "\n",
    "\n",
    "# for i in range(500):\n",
    "#     f = np.random.uniform(1,10)\n",
    "#     train_data.append((np.array([np.sin(f * i) for i in np.linspace(0, 20, 1000)]).astype(np.float32)))\n",
    "#     train_labels.append(float(f))\n",
    "    \n",
    "#     f_test = np.random.uniform(1,10)\n",
    "#     test_data.append((np.array([np.sin(f_test * i) for i in np.linspace(0, 20, 1000)]).astype(np.float32)))\n",
    "#     test_labels.append(float(f_test))\n",
    "\n",
    "# train_data = np.array(train_data)\n",
    "# train_labels = np.array(train_labels)\n",
    "\n",
    "# test_data = np.array(test_data)\n",
    "# test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "90d28980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create data tensors for dummy data\n",
    "# # train_data_ = torch.stack(train_data)\n",
    "# # train_labels_ = torch.Tensor(train_labels)\n",
    "\n",
    "# # test_data_ = torch.stack(test_data)\n",
    "# # test_labels_ = torch.Tensor(test_labels)\n",
    "\n",
    "# tensor_train_data = torch.Tensor(train_data)\n",
    "# tensor_train_labels = torch.Tensor(train_labels)\n",
    "\n",
    "# tensor_test_data = torch.Tensor(test_data)\n",
    "# tensor_test_labels = torch.Tensor(test_labels)\n",
    "\n",
    "# train_dataset = TensorDataset(tensor_train_data, tensor_train_labels)\n",
    "# test_dataset = TensorDataset(tensor_test_data, tensor_test_labels)\n",
    "\n",
    "\n",
    "# # train_data = (train_data_ - torch.mean(train_data_)) / torch.std(torch.max(train_data_))\n",
    "# # test_data = (test_data_ - torch.mean(test_data_)) / torch.std(torch.max(test_data_))\n",
    "\n",
    "\n",
    "# # # Load tensors into class for torch DataLoaders\n",
    "# # train_data = Data(train_dataset)\n",
    "# # test_data = Data(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a929cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DataLoader Parameters\n",
    "# loader_params = {\n",
    "#     \"batch_size\":  50, \n",
    "#     \"shuffle\":     True,\n",
    "#     \"num_workers\": 0\n",
    "# }\n",
    "\n",
    "# # Create DataLoader for training data\n",
    "# loader = DataLoader(train_dataset, **loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb9b74f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:297: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ..\\aten\\src\\ATen\\native\\Convolution.cpp:647.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 55.6049\n",
      "Epoch [2/50], Loss: 38.6558\n",
      "Epoch [3/50], Loss: 20.2157\n",
      "Epoch [4/50], Loss: 30.7112\n",
      "Epoch [5/50], Loss: 25.0720\n",
      "Epoch [6/50], Loss: 13.9100\n",
      "Epoch [7/50], Loss: 31.9539\n",
      "Epoch [8/50], Loss: 49.8780\n",
      "Epoch [9/50], Loss: 36.8339\n",
      "Epoch [10/50], Loss: 21.5013\n",
      "Epoch [11/50], Loss: 10.1994\n",
      "Epoch [12/50], Loss: 18.2315\n",
      "Epoch [13/50], Loss: 23.0485\n",
      "Epoch [14/50], Loss: 36.9669\n",
      "Epoch [15/50], Loss: 12.3179\n",
      "Epoch [16/50], Loss: 32.2275\n",
      "Epoch [17/50], Loss: 21.8762\n",
      "Epoch [18/50], Loss: 34.5440\n",
      "Epoch [19/50], Loss: 15.9651\n",
      "Epoch [20/50], Loss: 15.5056\n",
      "Epoch [21/50], Loss: 23.2938\n",
      "Epoch [22/50], Loss: 21.0300\n",
      "Epoch [23/50], Loss: 17.4086\n",
      "Epoch [24/50], Loss: 20.2770\n",
      "Epoch [25/50], Loss: 39.4670\n",
      "Epoch [26/50], Loss: 11.3965\n",
      "Epoch [27/50], Loss: 14.7045\n",
      "Epoch [28/50], Loss: 32.8229\n",
      "Epoch [29/50], Loss: 21.9086\n",
      "Epoch [30/50], Loss: 17.1291\n",
      "Epoch [31/50], Loss: 26.0479\n",
      "Epoch [32/50], Loss: 40.9243\n",
      "Epoch [33/50], Loss: 35.4108\n",
      "Epoch [34/50], Loss: 27.9002\n",
      "Epoch [35/50], Loss: 29.8394\n",
      "Epoch [36/50], Loss: 22.2214\n",
      "Epoch [37/50], Loss: 23.8001\n",
      "Epoch [38/50], Loss: 16.2139\n",
      "Epoch [39/50], Loss: 20.1203\n",
      "Epoch [40/50], Loss: 14.7474\n",
      "Epoch [41/50], Loss: 10.6991\n",
      "Epoch [42/50], Loss: 7.1254\n",
      "Epoch [43/50], Loss: 21.1650\n",
      "Epoch [44/50], Loss: 24.9085\n",
      "Epoch [45/50], Loss: 28.3010\n",
      "Epoch [46/50], Loss: 27.1780\n",
      "Epoch [47/50], Loss: 11.2462\n",
      "Epoch [48/50], Loss: 14.3078\n",
      "Epoch [49/50], Loss: 19.4134\n",
      "Epoch [50/50], Loss: 13.0318\n",
      "1690.7364466190338\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import time\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "def train(num_epochs, cnn, loader):\n",
    "    cnn.train()\n",
    "    \n",
    "    accum = 8\n",
    "    \n",
    "    total_step = len(loader)\n",
    "    \n",
    "    for epoch in range(num_epochs):        \n",
    "        for i, (signal, label) in enumerate(loader):\n",
    "            # Send data to device\n",
    "            signal, label = signal.to(device), label.to(device)\n",
    "            signal = torch.unsqueeze(signal, 1)\n",
    "            \n",
    "            with torch.set_grad_enabled(True):\n",
    "                # Pass inputs through net and obtain outputs\n",
    "                output = cnn(signal)\n",
    "\n",
    "                # Cast type to float and flatten results\n",
    "                output = output.to(torch.float)\n",
    "                output = torch.squeeze(output)\n",
    "                label = label.to(torch.float)\n",
    "                \n",
    "#                 print(output.shape)\n",
    "#                 print(label.shape)\n",
    "            \n",
    "                # Call loss function on net outputs\n",
    "                loss = loss_func(output, label)\n",
    "\n",
    "    #             a = list(cnn.parameters())[0].clone()\n",
    "\n",
    "                # Computes gradients for weights\n",
    "                loss.backward()            \n",
    "\n",
    "                if ((i + 1) % accum == 0) or (i + 1 == len(loader)):\n",
    "                    # Apply gradients using optimiser policy\n",
    "                    optimiser.step()\n",
    "\n",
    "                    # Zero network gradients\n",
    "                    optimiser.zero_grad()\n",
    "\n",
    "#                 print(list(cnn.parameters())[0].grad)\n",
    "    #             b = list(cnn.parameters())[0].clone()\n",
    "\n",
    "    #             print(torch.equal(a.data, b.data))\n",
    "\n",
    "            \n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "train(num_epochs, cnn, loader)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "5ff4df6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3-dimensional input for 3-dimensional weight[8, 256, 8], but got 4-dimensional input of size [1, 1, 256, 1023] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-254-105d2e5164a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Pearson r of the model is %.2f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-254-105d2e5164a3>\u001b[0m in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;31m# Get output of net, append to lists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-248-53da6f6192ac>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    295\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m--> 297\u001b[1;33m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    298\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 3-dimensional input for 3-dimensional weight[8, 256, 8], but got 4-dimensional input of size [1, 1, 256, 1023] instead"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "# Create test DataLoader\n",
    "test_loader = DataLoader(test_dataset, **loader_params)\n",
    "\n",
    "def test():\n",
    "    cnn.eval()\n",
    "    \n",
    "    predictions = np.array([])\n",
    "    labels = np.array([])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (signal, label) in enumerate(test_loader):\n",
    "            # Send input to device\n",
    "            signal = torch.Tensor(signal).to(device)\n",
    "            signal = torch.unsqueeze(signal,1)\n",
    "            \n",
    "            # Get output of net, append to lists\n",
    "            output = cnn(signal).cpu().detach().numpy()\n",
    "            predictions = np.append(predictions, output)            \n",
    "            labels = np.append(labels, label)\n",
    "\n",
    "    p_max = max(predictions)\n",
    "    p_min = min(predictions)\n",
    "    scaled_predictions = []\n",
    "    \n",
    "    for i in predictions:\n",
    "        scaled_predictions.append(((i - p_min) / (p_max - p_min)) * (10 - 1) + 1)\n",
    "            \n",
    "    print(scaled_predictions, labels)\n",
    "    \n",
    "    r = scipy.stats.pearsonr(scaled_predictions, labels)\n",
    "    \n",
    "    print('Pearson r of the model is %.2f' % r[0])\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ede4c795",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "261120it [08:03, 539.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.82579708  8.5583477   7.71505833 ... 16.63234711 13.95572281\n",
      " 16.84137726]\n",
      "[ 0.546314    0.546314    0.546314   ... 34.99910736 34.99910736\n",
      " 34.99910736]\n",
      "(261120,)\n",
      "Pearson r of the model is 0.82\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "# DataLoader Parameters\n",
    "loader_params = {\n",
    "    \"batch_size\":  1, \n",
    "    \"shuffle\":     False,\n",
    "    \"num_workers\": 0\n",
    "}\n",
    "\n",
    "# Create test DataLoader\n",
    "test_loader = DataLoader(test_dataset, **loader_params)\n",
    "\n",
    "def test():\n",
    "    cnn.eval()\n",
    "    \n",
    "    # Initialise arrays and dict\n",
    "    predictions = np.array([])\n",
    "    labels = np.array([])\n",
    "    averaged_dict = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (signal, label) in tqdm(enumerate(test_loader)):\n",
    "            # Send input to device\n",
    "            signal = torch.Tensor(signal).to(device)\n",
    "            signal = torch.unsqueeze(signal, 1)\n",
    "             \n",
    "            # Get output of net, append to lists\n",
    "            output = torch.squeeze(cnn(signal)).cpu().detach().numpy()\n",
    "            predictions = np.append(predictions, output)            \n",
    "            labels = np.append(labels, label)\n",
    "        \n",
    "#             print(output, label)\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] not in averaged_dict:\n",
    "                averaged_dict[labels[i]] = [predictions[i]]\n",
    "            else:\n",
    "                averaged_dict[labels[i]].append(predictions[i])\n",
    "            \n",
    "    for i in averaged_dict:\n",
    "        averaged_dict[i] = np.mean(averaged_dict[i])\n",
    "    \n",
    "    averaged_predictions = []\n",
    "    ordered_labels = []\n",
    "        \n",
    "    for i in averaged_dict:\n",
    "        ordered_labels.append(i)\n",
    "        averaged_predictions.append(averaged_dict[i])\n",
    "    \n",
    "    print(predictions)\n",
    "    print(labels)\n",
    "    print(labels.shape)\n",
    "    \n",
    "#     r = scipy.stats.pearsonr(predictions, labels)\n",
    "    \n",
    "    r = scipy.stats.pearsonr(averaged_predictions, ordered_labels)\n",
    "    \n",
    "    print('Pearson r of the model is %.2f' % r[0])\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9661c2d0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
