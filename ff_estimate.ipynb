{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose device for torch computing\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change working directory to labels\n",
    "work_dir = \"C:/file_lists_with_labels_ff_estimator\"\n",
    "os.chdir(work_dir)\n",
    "\n",
    "# Reads labels into dict of (filename: ff_value)\n",
    "training_data_labels = {}\n",
    "with open(\"training.txt\") as f:\n",
    "    for line in f:\n",
    "        key, val = line.split()\n",
    "        training_data_labels[key] = float(val)\n",
    "        \n",
    "test_data_labels = {}\n",
    "with open(\"test.txt\") as f:\n",
    "    for line in f:\n",
    "        key, val = line.split()\n",
    "        test_data_labels[key] = float(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2040/2040 [00:48<00:00, 41.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2040/2040 [00:47<00:00, 42.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Change directory to data\n",
    "os.chdir(\"C:\\\\rf_without_tgc\")\n",
    "\n",
    "# Iterate thru data to create lists of tensors\n",
    "training_data = []\n",
    "training_labels = []\n",
    "for file in tqdm(os.listdir()):\n",
    "    if file not in training_data_labels:\n",
    "        continue\n",
    "        \n",
    "    file_data = pd.read_csv(file, header=None).T\n",
    "    \n",
    "    x_tensor = file_data.to_numpy().astype(np.float32)\n",
    "    y_tensor = float(training_data_labels[file])\n",
    "    \n",
    "    for x in x_tensor:\n",
    "        training_data.append(x)\n",
    "        training_labels.append(y_tensor)\n",
    "    \n",
    "test_data = []\n",
    "test_labels = []\n",
    "for file in tqdm(os.listdir()):\n",
    "    if file not in test_data_labels:\n",
    "        continue\n",
    "        \n",
    "    file_data = pd.read_csv(file, header=None).T\n",
    "    \n",
    "    x_tensor = file_data.to_numpy().astype(np.float32)\n",
    "    y_tensor = float(test_data_labels[file])\n",
    "\n",
    "    for x in x_tensor:\n",
    "        test_data.append(x)\n",
    "        test_labels.append(y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(261120, 1024)\n",
      "(261120, 1024)\n"
     ]
    }
   ],
   "source": [
    "# # Create class for DataLoader compatability\n",
    "# class Data():\n",
    "#     def __init__(self, x, y):\n",
    "#         self.x = x\n",
    "#         self.y = y\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.x)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         X = self.x[idx]\n",
    "#         y =  self.y[idx]\n",
    "\n",
    "#         return X, y\n",
    "\n",
    "training_data = np.array(training_data)\n",
    "training_labels = np.array(training_labels)\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(training_data.shape)\n",
    "print(test_data.shape)\n",
    "    \n",
    "# training_data = np.swapaxes(training_data, 1, 2)\n",
    "# test_data = np.swapaxes(test_data, 1, 2)\n",
    "\n",
    "# Create data tensors\n",
    "training_data = torch.Tensor(training_data)\n",
    "training_labels = torch.Tensor(training_labels)\n",
    "\n",
    "test_data = torch.Tensor(test_data)\n",
    "test_labels = torch.Tensor(test_labels)\n",
    "\n",
    "# training_data = (training_data - torch.mean(training_data)) / torch.std(training_data)\n",
    "# test_data = (test_data - torch.mean(test_data)) / torch.std(test_data)\n",
    "\n",
    "train_dataset = TensorDataset(training_data, training_labels)\n",
    "test_dataset = TensorDataset(test_data, test_labels)\n",
    "\n",
    "# # Load tensors into class for torch DataLoaders\n",
    "# train_data = Data(training_data, training_labels)\n",
    "# test_data = Data(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader Parameters\n",
    "loader_params = {\n",
    "    \"batch_size\":  32, \n",
    "    \"shuffle\":     True,\n",
    "    \"num_workers\": 0\n",
    "}\n",
    "\n",
    "# Create DataLoader for training data\n",
    "loader = DataLoader(train_dataset, **loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "pool = 4\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 8, 8, 1, padding='same'),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool1d(pool, stride=pool, padding=0)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(8, 8, 4, 1, padding='same'),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool1d(pool, stride=pool, padding=0)\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(8, 16, 4, 1, padding='same'),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool1d(pool, stride=pool, padding=0)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(256, 32),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# import torch.nn as nn\n",
    "\n",
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "        \n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             nn.Conv2d(1, 8, 16, 1, 'same'),\n",
    "#             nn.Tanh(),\n",
    "#             nn.MaxPool2d(2, stride=2, padding=0)\n",
    "#         )\n",
    "        \n",
    "#         self.conv2 = nn.Sequential(\n",
    "#             nn.Conv2d(8, 8, 8, 1, padding='same'),\n",
    "#             nn.Tanh(),\n",
    "#             nn.MaxPool2d(2, stride=2, padding=0)\n",
    "#         )\n",
    "        \n",
    "#         self.conv3 = nn.Sequential(\n",
    "#             nn.Conv2d(8, 16, 8, 1, padding='same'),\n",
    "#             nn.Tanh(),\n",
    "#             nn.MaxPool2d(2, stride=2, padding=0)\n",
    "#         )\n",
    "        \n",
    "#         self.fc1 = nn.Sequential(\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(65024, 32),\n",
    "#             nn.Tanh()\n",
    "#         )\n",
    "        \n",
    "#         self.fc2 = nn.Linear(32, 2)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.conv3(x)\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(1, 8, kernel_size=(8,), stride=(1,), padding=same)\n",
       "    (1): Tanh()\n",
       "    (2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv1d(8, 8, kernel_size=(4,), stride=(1,), padding=same)\n",
       "    (1): Tanh()\n",
       "    (2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv1d(8, 16, kernel_size=(4,), stride=(1,), padding=same)\n",
       "    (1): Tanh()\n",
       "    (2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise net and push to computing device\n",
    "cnn = CNN()\n",
    "cnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Define optimiser and learning rate\n",
    "optimiser = optim.Adagrad(cnn.parameters(), lr=.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willi\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:298: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\Convolution.cpp:744.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 63.0360\n",
      "Epoch [2/50], Loss: 41.7159\n",
      "Epoch [3/50], Loss: 89.9523\n",
      "Epoch [4/50], Loss: 48.8297\n",
      "Epoch [5/50], Loss: 21.8218\n",
      "Epoch [6/50], Loss: 36.5319\n",
      "Epoch [7/50], Loss: 27.3808\n",
      "Epoch [8/50], Loss: 13.1044\n",
      "Epoch [9/50], Loss: 33.9479\n",
      "Epoch [10/50], Loss: 32.5101\n",
      "Epoch [11/50], Loss: 18.9605\n",
      "Epoch [12/50], Loss: 29.7588\n",
      "Epoch [13/50], Loss: 26.5330\n",
      "Epoch [14/50], Loss: 12.3110\n",
      "Epoch [15/50], Loss: 23.9676\n",
      "Epoch [16/50], Loss: 37.0451\n",
      "Epoch [17/50], Loss: 30.7373\n",
      "Epoch [18/50], Loss: 25.9636\n",
      "Epoch [19/50], Loss: 19.2997\n",
      "Epoch [20/50], Loss: 20.4021\n",
      "Epoch [21/50], Loss: 14.8886\n",
      "Epoch [22/50], Loss: 17.3342\n",
      "Epoch [23/50], Loss: 32.8667\n",
      "Epoch [24/50], Loss: 31.1784\n",
      "Epoch [25/50], Loss: 33.4727\n",
      "Epoch [26/50], Loss: 33.5238\n",
      "Epoch [27/50], Loss: 16.9639\n",
      "Epoch [28/50], Loss: 15.8366\n",
      "Epoch [29/50], Loss: 26.0659\n",
      "Epoch [30/50], Loss: 30.1807\n",
      "Epoch [31/50], Loss: 16.9325\n",
      "Epoch [32/50], Loss: 15.8137\n",
      "Epoch [33/50], Loss: 30.1081\n",
      "Epoch [34/50], Loss: 27.5613\n",
      "Epoch [35/50], Loss: 18.4107\n",
      "Epoch [36/50], Loss: 34.5016\n",
      "Epoch [37/50], Loss: 10.4844\n",
      "Epoch [38/50], Loss: 14.7675\n",
      "Epoch [39/50], Loss: 17.6468\n",
      "Epoch [40/50], Loss: 19.2148\n",
      "Epoch [41/50], Loss: 17.4479\n",
      "Epoch [42/50], Loss: 26.9989\n",
      "Epoch [43/50], Loss: 22.5755\n",
      "Epoch [44/50], Loss: 23.9243\n",
      "Epoch [45/50], Loss: 24.0681\n",
      "Epoch [46/50], Loss: 41.4458\n",
      "Epoch [47/50], Loss: 18.2404\n",
      "Epoch [48/50], Loss: 17.7990\n",
      "Epoch [49/50], Loss: 18.4000\n",
      "Epoch [50/50], Loss: 19.0057\n",
      "918.4888725280762\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import time\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "def train(num_epochs, cnn, loader):\n",
    "    cnn.train()\n",
    "    \n",
    "    accum = 8\n",
    "    \n",
    "    total_step = len(loader)\n",
    "    \n",
    "    for epoch in range(num_epochs):        \n",
    "        for i, (signal, label) in enumerate(loader):\n",
    "            # Send data to device\n",
    "            signal, label = signal.to(device), label.to(device)\n",
    "            signal = torch.unsqueeze(signal, 1)\n",
    "            \n",
    "            with torch.set_grad_enabled(True):\n",
    "                # Pass inputs through net and obtain outputs\n",
    "                output = cnn(signal)\n",
    "\n",
    "                # Cast type to float and flatten results\n",
    "                output = output.to(torch.float)\n",
    "                output = torch.squeeze(output)\n",
    "                label = label.to(torch.float)\n",
    "                \n",
    "#                 print(output.shape)\n",
    "#                 print(label.shape)\n",
    "            \n",
    "                # Call loss function on net outputs\n",
    "                loss = loss_func(output, label)\n",
    "\n",
    "    #             a = list(cnn.parameters())[0].clone()\n",
    "\n",
    "                # Computes gradients for weights\n",
    "                loss.backward()            \n",
    "\n",
    "                if ((i + 1) % accum == 0) or (i + 1 == len(loader)):\n",
    "                    # Apply gradients using optimiser policy\n",
    "                    optimiser.step()\n",
    "\n",
    "                    # Zero network gradients\n",
    "                    optimiser.zero_grad()\n",
    "\n",
    "#                 print(list(cnn.parameters())[0].grad)\n",
    "    #             b = list(cnn.parameters())[0].clone()\n",
    "\n",
    "    #             print(torch.equal(a.data, b.data))\n",
    "\n",
    "            \n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "train(num_epochs, cnn, loader)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "261120it [06:19, 688.76it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.76714325 10.56886196  9.62124825 ... 17.52271843 14.27943325\n",
      " 18.94706917]\n",
      "[ 0.546314    0.546314    0.546314   ... 34.99910736 34.99910736\n",
      " 34.99910736]\n",
      "(261120,)\n",
      "Pearson r of the model is 0.82\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "# DataLoader Parameters\n",
    "loader_params = {\n",
    "    \"batch_size\":  1, \n",
    "    \"shuffle\":     False,\n",
    "    \"num_workers\": 0\n",
    "}\n",
    "\n",
    "# Create test DataLoader\n",
    "test_loader = DataLoader(test_dataset, **loader_params)\n",
    "\n",
    "def test():\n",
    "    cnn.eval()\n",
    "    \n",
    "    # Initialise arrays and dict\n",
    "    predictions = np.array([])\n",
    "    labels = np.array([])\n",
    "    averaged_dict = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (signal, label) in tqdm(enumerate(test_loader)):\n",
    "            # Send input to device\n",
    "            signal = torch.Tensor(signal).to(device)\n",
    "            signal = torch.unsqueeze(signal, 1)\n",
    "             \n",
    "            # Get output of net, append to lists\n",
    "            output = torch.squeeze(cnn(signal)).cpu().detach().numpy()\n",
    "            predictions = np.append(predictions, output)            \n",
    "            labels = np.append(labels, label)\n",
    "        \n",
    "#             print(output, label)\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] not in averaged_dict:\n",
    "                averaged_dict[labels[i]] = [predictions[i]]\n",
    "            else:\n",
    "                averaged_dict[labels[i]].append(predictions[i])\n",
    "            \n",
    "    for i in averaged_dict:\n",
    "        averaged_dict[i] = np.mean(averaged_dict[i])\n",
    "    \n",
    "    averaged_predictions = []\n",
    "    ordered_labels = []\n",
    "        \n",
    "    for i in averaged_dict:\n",
    "        ordered_labels.append(i)\n",
    "        averaged_predictions.append(averaged_dict[i])\n",
    "    \n",
    "    print(predictions)\n",
    "    print(labels)\n",
    "    print(labels.shape)\n",
    "    \n",
    "#     r = scipy.stats.pearsonr(predictions, labels)\n",
    "    \n",
    "    r = scipy.stats.pearsonr(averaged_predictions, ordered_labels)\n",
    "    \n",
    "    print('Pearson r of the model is %.2f' % r[0])\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
