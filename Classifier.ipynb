{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c0fe1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b90009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a4f41bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = \"D:\\\\UIUC\\\\Fall 2021\\\\Research\"\n",
    "os.chdir(work_dir)\n",
    "\n",
    "# Reads labels into dict of (filename: value)\n",
    "training_data_labels = {}\n",
    "with open(\"training_classifier.txt\") as f:\n",
    "    for line in f:\n",
    "        key, val = line.split()\n",
    "        training_data_labels[key] = int(val)\n",
    "        \n",
    "test_data_labels = {}\n",
    "with open(\"test_classifier.txt\") as f:\n",
    "    for line in f:\n",
    "        key, val = line.split()\n",
    "        test_data_labels[key] = int(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6b4ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersect = 0\n",
    "# for i in training_data_labels:\n",
    "#     if i in test_data_labels:\n",
    "#         intersect += 1\n",
    "        \n",
    "# print(len(training_data_labels), len(test_data_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbe4a678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2040/2040 [01:27<00:00, 23.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2040/2040 [01:25<00:00, 23.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# Change directory to data\n",
    "os.chdir(\"D:\\\\UIUC\\\\Fall 2021\\\\Research\\\\rf_without_tgc\")\n",
    "\n",
    "# Iterate thru data to create lists of tensors\n",
    "training_data = []\n",
    "training_labels = []\n",
    "for file in tqdm(os.listdir()):\n",
    "    if file not in training_data_labels:\n",
    "        continue\n",
    "        \n",
    "    file_data = pd.read_csv(file, header=None).T\n",
    "    \n",
    "    x_tensor = file_data.to_numpy().astype(np.float32)\n",
    "    y_tensor = int(training_data_labels[file])\n",
    "    \n",
    "    for x in x_tensor:\n",
    "        training_data.append(x)\n",
    "        training_labels.append(y_tensor)\n",
    "    \n",
    "test_data = []\n",
    "test_labels = []\n",
    "for file in tqdm(os.listdir()):\n",
    "    if file not in test_data_labels:\n",
    "        continue\n",
    "        \n",
    "    file_data = pd.read_csv(file, header=None).T\n",
    "    \n",
    "    x_tensor = file_data.to_numpy().astype(np.float32)\n",
    "    y_tensor = int(test_data_labels[file])\n",
    "\n",
    "    for x in x_tensor:\n",
    "        test_data.append(x)\n",
    "        test_labels.append(y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb897249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(261120, 1024)\n",
      "(261120, 1024)\n"
     ]
    }
   ],
   "source": [
    "# # Create class for DataLoader compatability\n",
    "# class Data():\n",
    "#     def __init__(self, x, y):\n",
    "#         self.x = x\n",
    "#         self.y = y\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.x)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         X = self.x[idx]\n",
    "#         y =  self.y[idx]\n",
    "\n",
    "#         return X, y\n",
    "\n",
    "training_data = np.array(training_data)\n",
    "training_labels = np.array(training_labels)\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(training_data.shape)\n",
    "print(test_data.shape)\n",
    "    \n",
    "# training_data = np.swapaxes(training_data, 1, 2)\n",
    "# test_data = np.swapaxes(test_data, 1, 2)\n",
    "\n",
    "# Create data tensors\n",
    "training_data = torch.Tensor(training_data)\n",
    "training_labels = torch.Tensor(training_labels)\n",
    "\n",
    "test_data = torch.Tensor(test_data)\n",
    "test_labels = torch.Tensor(test_labels)\n",
    "\n",
    "# training_data = (training_data - torch.mean(training_data)) / torch.std(training_data)\n",
    "# test_data = (test_data - torch.mean(test_data)) / torch.std(test_data)\n",
    "\n",
    "train_dataset = TensorDataset(training_data, training_labels)\n",
    "test_dataset = TensorDataset(test_data, test_labels)\n",
    "\n",
    "# # Load tensors into class for torch DataLoaders\n",
    "# train_data = Data(training_data, training_labels)\n",
    "# test_data = Data(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://shashikachamod4u.medium.com/excel-csv-to-pytorch-dataset-def496b6bcc1\n",
    "# class FeatureDataset(Dataset):\n",
    "#     def __init__(self, file_name):\n",
    "#         x = pd.read_csv(file_name).iloc[1:700]\n",
    "#         y = [random.randint(0, 1) for i in range(x.shape[0])]\n",
    "\n",
    "#         sc = StandardScaler()\n",
    "#         x_train = sc.fit_transform(x)\n",
    "#         y_train = y\n",
    "        \n",
    "#         self.x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "#         self.y_train = torch.tensor(y_train)\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.y_train)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.x_train[idx], self.y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fcc3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://shashikachamod4u.medium.com/excel-csv-to-pytorch-dataset-def496b6bcc1\n",
    "# class TestDataset(Dataset):\n",
    "#     def __init__(self, file_name):\n",
    "#         x = pd.read_csv(file_name).iloc[700:]\n",
    "#         y = [random.randint(0, 1) for i in range(x.shape[0])]\n",
    "\n",
    "#         sc = StandardScaler()\n",
    "#         x_train = sc.fit_transform(x)\n",
    "#         y_train = y\n",
    "        \n",
    "#         self.x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "#         self.y_train = torch.tensor(y_train)\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.y_train)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.x_train[idx], self.y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2511a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_params = {\n",
    "    \"batch_size\":  32, \n",
    "    \"shuffle\":     True,\n",
    "    \"num_workers\": 0\n",
    "}\n",
    "\n",
    "loader = DataLoader(train_dataset, **loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d5f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# loaders = {\n",
    "#     'train': torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=True, num_workers=0),\n",
    "#     'test': torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True, num_workers=0),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4089d68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "pool = 4\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 8, 8, 1, padding='same'),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool1d(pool, stride=pool, padding=0)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(8, 8, 4, 1, padding='same'),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool1d(pool, stride=pool, padding=0)\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(8, 16, 4, 1, padding='same'),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool1d(pool, stride=pool, padding=0)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(256, 32),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# import torch.nn as nn\n",
    "\n",
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "        \n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             nn.Conv2d(1, 8, 16, 1, 'same'),\n",
    "#             nn.Tanh(),\n",
    "#             nn.MaxPool2d(4, stride=4, padding=0)\n",
    "#         )\n",
    "        \n",
    "#         self.conv2 = nn.Sequential(\n",
    "#             nn.Conv2d(8, 8, 8, 1, padding='same'),\n",
    "#             nn.Tanh(),\n",
    "#             nn.MaxPool2d(4, stride=4, padding=0)\n",
    "#         )\n",
    "        \n",
    "#         self.conv3 = nn.Sequential(\n",
    "#             nn.Conv2d(8, 16, 8, 1, padding='same'),\n",
    "#             nn.Tanh(),\n",
    "#             nn.MaxPool2d(4, stride=4, padding=0)\n",
    "#         )\n",
    "        \n",
    "#         self.fc1 = nn.Sequential(\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(960, 32),\n",
    "#             nn.Tanh()\n",
    "#         )\n",
    "        \n",
    "#         self.fc2 = nn.Linear(32, 2)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.conv3(x)\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09329fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(1, 8, kernel_size=(8,), stride=(1,), padding=same)\n",
       "    (1): Tanh()\n",
       "    (2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv1d(8, 8, kernel_size=(4,), stride=(1,), padding=same)\n",
       "    (1): Tanh()\n",
       "    (2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv1d(8, 16, kernel_size=(4,), stride=(1,), padding=same)\n",
       "    (1): Tanh()\n",
       "    (2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "cnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eec5f8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0918ebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimiser = optim.Adagrad(cnn.parameters(), lr=.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb9b74f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.1811\n",
      "Epoch [2/50], Loss: 0.1530\n",
      "Epoch [3/50], Loss: 0.0802\n",
      "Epoch [4/50], Loss: 0.0523\n",
      "Epoch [5/50], Loss: 0.0968\n",
      "Epoch [6/50], Loss: 0.2381\n",
      "Epoch [7/50], Loss: 0.2489\n",
      "Epoch [8/50], Loss: 0.0804\n",
      "Epoch [9/50], Loss: 0.0809\n",
      "Epoch [10/50], Loss: 0.3418\n",
      "Epoch [11/50], Loss: 0.0791\n",
      "Epoch [12/50], Loss: 0.1619\n",
      "Epoch [13/50], Loss: 0.0641\n",
      "Epoch [14/50], Loss: 0.1042\n",
      "Epoch [15/50], Loss: 0.1323\n",
      "Epoch [16/50], Loss: 0.2571\n",
      "Epoch [17/50], Loss: 0.2621\n",
      "Epoch [18/50], Loss: 0.0892\n",
      "Epoch [19/50], Loss: 0.0474\n",
      "Epoch [20/50], Loss: 0.2253\n",
      "Epoch [21/50], Loss: 0.0553\n",
      "Epoch [22/50], Loss: 0.0641\n",
      "Epoch [23/50], Loss: 0.1858\n",
      "Epoch [24/50], Loss: 0.0492\n",
      "Epoch [25/50], Loss: 0.1079\n",
      "Epoch [26/50], Loss: 0.0704\n",
      "Epoch [27/50], Loss: 0.0930\n",
      "Epoch [28/50], Loss: 0.0775\n",
      "Epoch [29/50], Loss: 0.0927\n",
      "Epoch [30/50], Loss: 0.2011\n",
      "Epoch [31/50], Loss: 0.0222\n",
      "Epoch [32/50], Loss: 0.2666\n",
      "Epoch [33/50], Loss: 0.0383\n",
      "Epoch [34/50], Loss: 0.0787\n",
      "Epoch [35/50], Loss: 0.1095\n",
      "Epoch [36/50], Loss: 0.0836\n",
      "Epoch [37/50], Loss: 0.0602\n",
      "Epoch [38/50], Loss: 0.1344\n",
      "Epoch [39/50], Loss: 0.1429\n",
      "Epoch [40/50], Loss: 0.0567\n",
      "Epoch [41/50], Loss: 0.0793\n",
      "Epoch [42/50], Loss: 0.0279\n",
      "Epoch [43/50], Loss: 0.0306\n",
      "Epoch [44/50], Loss: 0.0630\n",
      "Epoch [45/50], Loss: 0.0574\n",
      "Epoch [46/50], Loss: 0.0427\n",
      "Epoch [47/50], Loss: 0.0431\n",
      "Epoch [48/50], Loss: 0.0809\n",
      "Epoch [49/50], Loss: 0.1314\n",
      "Epoch [50/50], Loss: 0.0831\n",
      "2043.4616405963898\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import time\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "def train(num_epochs, cnn, loader):\n",
    "    cnn.train()\n",
    "    \n",
    "    accum = 8\n",
    "    \n",
    "    total_step = len(loader)\n",
    "\n",
    "    for epoch in range(num_epochs):        \n",
    "        for i, (signal, label) in enumerate(loader):\n",
    "            # Send data to device\n",
    "            signal, label = signal.to(device), label.to(device)\n",
    "            signal = torch.unsqueeze(signal, 1)\n",
    "            \n",
    "            with torch.set_grad_enabled(True):\n",
    "                # Pass inputs through net and obtain outputs\n",
    "                output = cnn(signal)\n",
    "\n",
    "                # Cast type to float and flatten results\n",
    "                output = output.to(torch.float)\n",
    "                output = torch.squeeze(output)\n",
    "                label = label.to(torch.int64)\n",
    "                \n",
    "#                 print(output.shape)\n",
    "#                 print(label.shape)\n",
    "            \n",
    "                # Call loss function on net outputs\n",
    "                loss = loss_func(output, label)\n",
    "\n",
    "    #             a = list(cnn.parameters())[0].clone()\n",
    "\n",
    "                # Computes gradients for weights\n",
    "                loss.backward()            \n",
    "\n",
    "                if ((i + 1) % accum == 0) or (i + 1 == len(loader)):\n",
    "                    # Apply gradients using optimiser policy\n",
    "                    optimiser.step()\n",
    "\n",
    "                    # Zero network gradients\n",
    "                    optimiser.zero_grad()\n",
    "\n",
    "#                 print(list(cnn.parameters())[0].grad)\n",
    "    #             b = list(cnn.parameters())[0].clone()\n",
    "\n",
    "    #             print(torch.equal(a.data, b.data))\n",
    "\n",
    "            \n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "train(num_epochs, cnn, loader)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4af5a117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 261120 test signals: 0.89\n"
     ]
    }
   ],
   "source": [
    "loader_params = {\n",
    "    \"batch_size\":  1, \n",
    "    \"shuffle\":     False,\n",
    "    \"num_workers\": 0\n",
    "}\n",
    "\n",
    "test_loader = DataLoader(test_dataset, **loader_params)\n",
    "\n",
    "def test():\n",
    "    cnn.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for i, (signal, label) in enumerate(test_loader):\n",
    "            signal = torch.Tensor(signal).to(device)\n",
    "            signal = torch.unsqueeze(signal, 1)\n",
    "            output = cnn(signal).cpu()\n",
    "            \n",
    "            labels.append(label.numpy())\n",
    "\n",
    "            pred_y = torch.max(output, 1)[1].data.squeeze().detach().numpy()\n",
    "            predictions.append(pred_y)\n",
    "        \n",
    "    averaged_predictions = []\n",
    "    \n",
    "    for i in predictions:\n",
    "        if np.mean(i) > .5:\n",
    "            averaged_predictions.append(1.)\n",
    "        else:\n",
    "            averaged_predictions.append(0.)\n",
    "        \n",
    "    averaged_labels = []\n",
    "    for i in labels:\n",
    "        averaged_labels.append(np.mean(i))\n",
    "\n",
    "    for i in range(len(averaged_labels)):\n",
    "        total += 1\n",
    "        if averaged_labels[i] == averaged_predictions[i]:\n",
    "            correct += 1\n",
    "#             for i in range(len(label)):\n",
    "#                 if pred_y[i] == label[i]:\n",
    "#                     correct += 1\n",
    "#                     total += 1\n",
    "#                 else:\n",
    "#                     total += 1\n",
    "            \n",
    "    print('Test Accuracy of the model on the %i test signals: %.2f' % (total, (correct / total)))\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567aa58f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
